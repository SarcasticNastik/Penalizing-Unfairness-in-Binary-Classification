{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6dcf9b0",
   "metadata": {},
   "source": [
    "## FPE Programming Assignment (15 Marks)\n",
    "\n",
    "### Implement the technique proposed in the paper \"Penalizing Unfairness in Binary Classification\" and reproduce the experimental results\n",
    "\n",
    "    - Find the paper here: https://arxiv.org/pdf/1707.00044.pdf\n",
    "    \n",
    "\n",
    "(6 marks) Reproduce the results shown in Table-1\n",
    "        \n",
    "           You need to implement the proposed method with AVD Penalizers and reproduce results for COMPAS dataset for all three Considerations shown in the table. Furthermore, you need to compare the above results with Zafar et al. and Zafar et al. Baseline for all three Considerations shown in the Table-1.\n",
    "           \n",
    "           \n",
    "(4 marks) Reproduce the results shown in Table-3\n",
    "          \n",
    "           You need to implement the proposed method with AVD Penalizers and Vanilla Regularized Logistic Regression, and reproduce results for all three datasets mentioned in the Table-3.\n",
    "\n",
    "          \n",
    "(5 marks) Reproduce the results shown in Figure-2 and 3\n",
    "          \n",
    "           You need to reproduce the plots shown in Figure-2 (COMPAS dataset) and Figure-3 (Adult Dataset).\n",
    "\n",
    "Note: All the experiments and details have to be clearly explained\n",
    "      \n",
    "      \n",
    "#### Kindly complete the code in the following notebook itself.\n",
    "\n",
    "#### The soft deadline for submission is 15th Nov. The hard deadline for submission is 28th Nov. with 20% penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd35ac5b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(42)\n",
    "\n",
    "NRUNS=5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab42f73",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "### COMPAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "122d02f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>compas_screening_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>...</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>v_screening_date</th>\n",
       "      <th>in_custody</th>\n",
       "      <th>out_custody</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>miguel</td>\n",
       "      <td>hernandez</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1947-04-18</td>\n",
       "      <td>69</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>2014-07-07</td>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>kevon</td>\n",
       "      <td>dixon</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>Male</td>\n",
       "      <td>1982-01-22</td>\n",
       "      <td>34</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>2013-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>ed</td>\n",
       "      <td>philo</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1991-05-14</td>\n",
       "      <td>24</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>marcu brown</td>\n",
       "      <td>marcu</td>\n",
       "      <td>brown</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-01-21</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>bouthy pierrelouis</td>\n",
       "      <td>bouthy</td>\n",
       "      <td>pierrelouis</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>Male</td>\n",
       "      <td>1973-01-22</td>\n",
       "      <td>43</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7209</th>\n",
       "      <td>10996</td>\n",
       "      <td>steven butler</td>\n",
       "      <td>steven</td>\n",
       "      <td>butler</td>\n",
       "      <td>2013-11-23</td>\n",
       "      <td>Male</td>\n",
       "      <td>1992-07-17</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2013-11-23</td>\n",
       "      <td>2013-11-22</td>\n",
       "      <td>2013-11-24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>860</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7210</th>\n",
       "      <td>10997</td>\n",
       "      <td>malcolm simmons</td>\n",
       "      <td>malcolm</td>\n",
       "      <td>simmons</td>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-03-25</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>2014-01-31</td>\n",
       "      <td>2014-02-02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>790</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7211</th>\n",
       "      <td>10999</td>\n",
       "      <td>winston gregory</td>\n",
       "      <td>winston</td>\n",
       "      <td>gregory</td>\n",
       "      <td>2014-01-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1958-10-01</td>\n",
       "      <td>57</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2014-01-14</td>\n",
       "      <td>2014-01-13</td>\n",
       "      <td>2014-01-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>808</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7212</th>\n",
       "      <td>11000</td>\n",
       "      <td>farrah jean</td>\n",
       "      <td>farrah</td>\n",
       "      <td>jean</td>\n",
       "      <td>2014-03-09</td>\n",
       "      <td>Female</td>\n",
       "      <td>1982-11-17</td>\n",
       "      <td>33</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>2014-03-09</td>\n",
       "      <td>2014-03-08</td>\n",
       "      <td>2014-03-09</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>754</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7213</th>\n",
       "      <td>11001</td>\n",
       "      <td>florencia sanmartin</td>\n",
       "      <td>florencia</td>\n",
       "      <td>sanmartin</td>\n",
       "      <td>2014-06-30</td>\n",
       "      <td>Female</td>\n",
       "      <td>1992-12-18</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>Low</td>\n",
       "      <td>2014-06-30</td>\n",
       "      <td>2015-03-15</td>\n",
       "      <td>2015-03-15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7214 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                 name      first         last  \\\n",
       "0         1     miguel hernandez     miguel    hernandez   \n",
       "1         3          kevon dixon      kevon        dixon   \n",
       "2         4             ed philo         ed        philo   \n",
       "3         5          marcu brown      marcu        brown   \n",
       "4         6   bouthy pierrelouis     bouthy  pierrelouis   \n",
       "...     ...                  ...        ...          ...   \n",
       "7209  10996        steven butler     steven       butler   \n",
       "7210  10997      malcolm simmons    malcolm      simmons   \n",
       "7211  10999      winston gregory    winston      gregory   \n",
       "7212  11000          farrah jean     farrah         jean   \n",
       "7213  11001  florencia sanmartin  florencia    sanmartin   \n",
       "\n",
       "     compas_screening_date     sex         dob  age          age_cat  \\\n",
       "0               2013-08-14    Male  1947-04-18   69  Greater than 45   \n",
       "1               2013-01-27    Male  1982-01-22   34          25 - 45   \n",
       "2               2013-04-14    Male  1991-05-14   24     Less than 25   \n",
       "3               2013-01-13    Male  1993-01-21   23     Less than 25   \n",
       "4               2013-03-26    Male  1973-01-22   43          25 - 45   \n",
       "...                    ...     ...         ...  ...              ...   \n",
       "7209            2013-11-23    Male  1992-07-17   23     Less than 25   \n",
       "7210            2014-02-01    Male  1993-03-25   23     Less than 25   \n",
       "7211            2014-01-14    Male  1958-10-01   57  Greater than 45   \n",
       "7212            2014-03-09  Female  1982-11-17   33          25 - 45   \n",
       "7213            2014-06-30  Female  1992-12-18   23     Less than 25   \n",
       "\n",
       "                  race  ...  v_decile_score  v_score_text  v_screening_date  \\\n",
       "0                Other  ...               1           Low        2013-08-14   \n",
       "1     African-American  ...               1           Low        2013-01-27   \n",
       "2     African-American  ...               3           Low        2013-04-14   \n",
       "3     African-American  ...               6        Medium        2013-01-13   \n",
       "4                Other  ...               1           Low        2013-03-26   \n",
       "...                ...  ...             ...           ...               ...   \n",
       "7209  African-American  ...               5        Medium        2013-11-23   \n",
       "7210  African-American  ...               5        Medium        2014-02-01   \n",
       "7211             Other  ...               1           Low        2014-01-14   \n",
       "7212  African-American  ...               2           Low        2014-03-09   \n",
       "7213          Hispanic  ...               4           Low        2014-06-30   \n",
       "\n",
       "      in_custody  out_custody  priors_count.1 start   end event two_year_recid  \n",
       "0     2014-07-07   2014-07-14               0     0   327     0              0  \n",
       "1     2013-01-26   2013-02-05               0     9   159     1              1  \n",
       "2     2013-06-16   2013-06-16               4     0    63     0              1  \n",
       "3            NaN          NaN               1     0  1174     0              0  \n",
       "4            NaN          NaN               2     0  1102     0              0  \n",
       "...          ...          ...             ...   ...   ...   ...            ...  \n",
       "7209  2013-11-22   2013-11-24               0     1   860     0              0  \n",
       "7210  2014-01-31   2014-02-02               0     1   790     0              0  \n",
       "7211  2014-01-13   2014-01-14               0     0   808     0              0  \n",
       "7212  2014-03-08   2014-03-09               3     0   754     0              0  \n",
       "7213  2015-03-15   2015-03-15               2     0   258     0              1  \n",
       "\n",
       "[7214 rows x 53 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = {}\n",
    "# Stores only the real values, use association to interpret the output\n",
    "dataset['compas'] = pd.read_csv('dataset/compas/compas-scores-two-years.csv')\n",
    "dataset['compas']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df964bcf",
   "metadata": {},
   "source": [
    "### Mapping input space to Reals \n",
    "\n",
    "1. COMPAS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ebf36cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = {}\n",
    "transform['compas'] = {\n",
    "    'race': {\n",
    "      'Caucasian': 0,\n",
    "      'African-American': 1\n",
    "    },\n",
    "    'sex': {\n",
    "        'Male': 0,\n",
    "        'Female': 1,\n",
    "    },\n",
    "    'c_charge_degree': {\n",
    "        'M': 0,\n",
    "        'F': 1\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b23143",
   "metadata": {},
   "source": [
    "### Input variables extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8be16573",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmt = {}\n",
    "fmt['compas'] = {\n",
    "    # 5 features where 1st feature is the protected attribute\n",
    "    'input_columns': ['race','age','sex','priors_count','c_charge_degree'], \n",
    "    'label_column': 'two_year_recid',\n",
    "    'name': 'compas',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46ccca7",
   "metadata": {},
   "source": [
    "## Set default problem parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0d2325d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = {}\n",
    "problem['compas'] = {\n",
    "    'c': (0, 400, 21),\n",
    "    'gamma': (0, 100, 11),\n",
    "    'validation_size': 0.5,\n",
    "#     'repetition': 5,\n",
    "    'folds': 5,\n",
    "    'fp': False,\n",
    "    'fn': False,\n",
    "    'test_size': 0.3,\n",
    "    'fair_penalty': False # AVD v/s Squared Loss\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbf6d15",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42300829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df, data_extract, transform):\n",
    "    \"\"\" \n",
    "    Parse the dataset according to data_extract \n",
    "    returns: X[:], y[:] where X are the stacked input variables (with x_1 being protected) and y is the corresponding label \n",
    "    \"\"\"\n",
    "    X = df[[*data_extract['input_columns']]]\n",
    "    y = df[[data_extract['label_column']]].values.reshape(-1,)\n",
    "    for header in X.columns:\n",
    "        if header in transform.keys():\n",
    "            X[header].replace(transform[header], inplace=True)\n",
    "            numeric_values = pd.to_numeric(X[header], errors='coerce').notnull()\n",
    "            X = X[numeric_values]\n",
    "            y = y[numeric_values]\n",
    "    X = X.values\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bacbbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(y, y_hat):\n",
    "    ones = np.ones(y.shape)\n",
    "    fp = y_hat.T @ (ones - y)\n",
    "    fn = (ones - y_hat).T @ (y)\n",
    "    pos = np.sum(y)\n",
    "    neg = np.sum(ones - y)\n",
    "\n",
    "    return {'fpr': (fp/neg).item(),\n",
    "            'fnr': (fn/pos).item(),\n",
    "            'acc': ((1 - fp + 1 - fn) / y.shape[0]).item()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79d3f9b",
   "metadata": {},
   "source": [
    "## Disparity b/w groups\n",
    "\n",
    "> Evaluated on the test set.\n",
    "\n",
    "\n",
    "### FPR\n",
    "\n",
    "$$\\textbf{D}_{FPR} = |FPR_{a=0}(\\hat{Y}) - FPR_{a=1}(\\hat{Y})|$$\n",
    "\n",
    "### FNR\n",
    "\n",
    "$$\\textbf{D}_{FNR} = |FNR_{a=0}(\\hat{Y}) - FNR_{a=1}(\\hat{Y})|$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fd38d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Disparity = {}\n",
    "Disparity['fpr'] = lambda prediction, label: np.sum(np.where((predictions == 1) & (label == 0), 1, 0)) / np.sum(np.where(label == 0))\n",
    "Disparity['fnr'] = lambda prediction, label: np.sum(np.where((predictions == 0) & (label == 1), 1, 0)) / np.sum(np.where(label == 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78268a24",
   "metadata": {},
   "source": [
    "# Formulating the problem in CVXPY\n",
    "\n",
    "For the logistic regression problem we need to find $(w, b) := w' \\in R^{dim_X+1}$ which minimizes the following loss for our model, along with corresponding fairness penalties with $d_1$ and $d_2$ set-up according to desired tradeoff b/w accuracy, FPR matching and FNR matching.\n",
    "\n",
    "$$\\begin{align}\n",
    "\\text{Objective: } &\\text{minimize}_{\\theta} &&L_S^{0-1}(\\theta) + d_1 \\textbf{D}_1 + d_2 \\textbf{D}_2\n",
    "\\end{align}$$\n",
    "\n",
    "Relaxed form of this loss (with additional $\\ell_2$ regularization term) gives us the formulation:\n",
    "$$\\begin{align}\n",
    "\\text{Proxy:} &\\text{minimize}&& \\ell\\ell(\\theta;S) + c_1R_{FP}(\\theta;S) + c_2R_{FN}(\\theta;S) + q \\| \\theta \\|^2.\n",
    "\\end{align}$$\n",
    " "
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "2a2c5298",
   "metadata": {},
   "source": [
    "# AVD Penalizers Method \n",
    "\n",
    "> Given $d_0$ and $d_1$.\n",
    "\n",
    "1. Split dataset at random into training set $S$ and test set $T$.\n",
    "2. For each $c$ in some range, perform **cross-validation** on $S$ to select the corresponding best value $q_c$ for the regularization parameter.\n",
    "3. For each $(c, q_c)$, let $$\\theta_c = \\text{argmin}_{\\theta}\\text{ Proxy}(\\theta;S,c, c,q_c)$$\n",
    "4. Select $\\theta^* \\in \\text{argmin}_{\\theta} \\text{ Objective}(\\theta_c;S,d_1,d_2)$\n",
    "5. Evaluate performance on test set $T$.\n",
    "\n",
    "Also, log-likelihood is:\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c186147",
   "metadata": {},
   "source": [
    "### REDACTED\n",
    "Note: Paper specifies 5-fold cross validation on the train dataset S available, but \n",
    "their implementation conforms with repeated cross-validation, specifically 5 2-fold\n",
    "cross validation (with validation size 0.5). have opted for the repeated cross-validation which better represents the observations.\n",
    "\n",
    "Rather, the cross validation is **shuffle split**.\n",
    "\n",
    "Rather, we have a *Shuffle split* system which samples our train and test sets for  validation at random for num times.\n",
    "Link: https://amueller.github.io/aml/04-model-evaluation/1-data-splitting-strategies.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5c233a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(X, y, c1, c2, gamma, w):\n",
    "    \"\"\" \n",
    "    Evaluate model `w` on dataset (X,y) based on objective and relaxed loss scores \n",
    "    returns: Dict(model=)\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'objective': {\n",
    "            'accuracy':0,\n",
    "            'w':w,\n",
    "            'loss': 0,#(1-accuracy_loss) + c_1 * \n",
    "        },\n",
    "        'relaxed': {\n",
    "            'loss': 0,#(logistic loss) + c1 * R_FP + c2 * R_FN + gamma * (w.T @ w),\n",
    "            'w': w,\n",
    "             'll': 0, #logistic loss,\n",
    "    \n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "63990e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_problem(X, y, problem):\n",
    "    \"\"\" Solve the optimization problem as defined in the paper: https://arxiv.org/pdf/1707.00044.pdf\"\"\"\n",
    "    from sklearn.model_selection import test_train_split\n",
    "    \n",
    "    range_c = np.linspace(problem['c'][0], problem['c'][1], num=problem['c'][2])\n",
    "    range_gamma = np.linspace(problem['gamma'][0], problem['gamma'][1], num=problem['gamma'][2])\n",
    "    \n",
    "    # 1. [x]\n",
    "    X_train_all, X_test_all , y_train_all , y_test_all = train_test_split(X, y, test_size=problem['test_size'], random_state=42)\n",
    "    \n",
    "    results_all = [list() for i in range(problem['c'][2])]  \n",
    "    optimal_gamma_map = {c:0 for c in range_c}\n",
    "    \n",
    "    # Finding optimal gamma for every `c` there can be\n",
    "    assert(problem['fn'] or problem['fp'], \"solve_problem called instead of vanilla regularizer\")\n",
    "    for i, val_c in enumerate(range_c):\n",
    "        tmp_results = [list() for i in range(problem['gamma'][2])]\n",
    "        for fold in range(problem['folds']):\n",
    "            # set random state variable for different folds\n",
    "            x_train_val, x_test_val, y_train_val, y_test_val = train_test_split(X_train_all, y_train_all, test_size=problem['validation_size'], random_state=i*10)\n",
    "\n",
    "            # Solve problem for all gammas\n",
    "            for idx, val_gamma in enumerate(range_gamma):\n",
    "                w, _ = solve_problem_instance(x_train_val, y_train_val, float(val_c if problem['fp'] == True else 0), \n",
    "                                              float(val_c if problem['fn'] == True else 0), val_gamma, \n",
    "                                              squared=True if problem['fair_penalty'] == 'AVD' else False)\n",
    "                # Store all the stats, D_FP, D_TP, Accuracy\n",
    "                tmp_results[idx].append(eval(x_test_val, y_test_val, w))\n",
    "\n",
    "        # Evaluate on the validation-held out set i.e. test set\n",
    "        for idx in range(len(range_gamma)):\n",
    "            # Accumulate results over all folds\n",
    "            # argmin according to losses\n",
    "            if True: # accuracy of this gamma better than best_gamma\n",
    "                best_gamma = 0\n",
    "                best_gamma_idx = idx\n",
    "\n",
    "        # Find optimal gamma for this particular C\n",
    "\n",
    "        # Accumulate the fold results\n",
    "        #    * Retrieve best model there is and store it\n",
    "\n",
    "        # Store best model association in the gamma map\n",
    "        # Set that as the final parameter\n",
    "\n",
    "        results_all.append() # append model results w.r.t c with best found hyperparameters \n",
    "    \n",
    "    # From all the models, choose the one performing best on objective loss over test set T.\n",
    "    return results_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4dd6ee",
   "metadata": {},
   "source": [
    "## Subpopulations Utils\n",
    "\n",
    "$$S_{a, y} = \\{x^i \\in S: x_1^i = a, y^i = y\\} \\quad \\text{for } a, y \\in \\{0, 1\\}$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c4e0b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = [[0, 0],[0, 0]]\n",
    "S[0][0] = lambda dataset, labels: dataset[np.where((dataset[:, 0] == 0) & (labels == 0))]\n",
    "S[0][1] = lambda dataset, labels: dataset[np.where((dataset[:, 0] == 0) & (labels == 1))]\n",
    "S[1][0] = lambda dataset, labels: dataset[np.where((dataset[:, 0] == 1) & (labels == 0))]\n",
    "S[1][1] = lambda dataset, labels: dataset[np.where((dataset[:, 0] == 1) & (labels == 1))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247158a6",
   "metadata": {},
   "source": [
    "## Absolute Value Difference Penalty\n",
    "\n",
    "$$R_{FP}^{AVD}(\\theta;S) = \\left| {\\theta}^T \\left(\\dfrac {\\sum\\limits_{x \\in S_{00}} x} { |S_{00}| } -  \\dfrac {\\sum\\limits_{x \\in S_{01}} x} { |S_{01}| }\\right) \\right|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9ae2c042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "R = {'AVD':{}, 'SD':{}}\n",
    "R['AVD']['FP'] = lambda S00, S01, theta: cp.abs(theta.T @ (np.sum(S00,axis=0) / S00.size[0] - np.sum(S01,axis=0) / S01.size[0]))\n",
    "R['AVD']['FN'] = lambda S10, S11, theta: cp.abs(theta.T @ (np.sum(S10,axis=0) / S10.size[0] - np.sum(S11,axis=0) / S11.size[0]))\n",
    "\n",
    "R['SD']['FP'] = lambda S00, S01, theta: cp.square(R['AVD']['FP'](S00, S01, theta))\n",
    "R['SD']['FN'] = lambda S10, S11, theta: cp.square(R['AVD']['FN'](S10, S11, theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9aa781c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_problem_instance(X, y, c_1, c_2, gamma, squared=False):\n",
    "    import cvxpy as cp\n",
    "    import numpy as np\n",
    "    \"\"\"\n",
    "    minimize log-likelihood + c_1 R_FP [**2] + c_2 R_FN [**2] + gamma \\|\\theta\\|^2_2\n",
    "    returns: w\n",
    "    \"\"\"\n",
    "    w = cp.Variable(X.shape[1])\n",
    "    \n",
    "    # Generate S for given dataset\n",
    "    #S_ay -> protected attribute = a, label = y\n",
    "    instanceS = [[0,0], [0,0]]\n",
    "    instanceS[0][0] = S[0][0](X, y)\n",
    "    instanceS[0][1] = S[0][1](X, y)\n",
    "    instanceS[1][0] = S[1][0](X, y)\n",
    "    instanceS[1][1] = S[1][1](X, y)\n",
    "    \n",
    "#     R_FP = R_FN = 0\n",
    "    \n",
    "    if squared == False:\n",
    "        R_FP = R['AVD']['FP'](instanceS[0][0], instanceS[0][1], w)\n",
    "        R_FN = R['AVD']['FN'](instanceS[1][0], instanceS[1][1], w)\n",
    "    else:\n",
    "        R_FP = R['SD']['FP'](instanceS[0][0], instanceS[0][1], w)\n",
    "        R_FN = R['SD']['FN'](instanceS[1][0], instanceS[1][1], w)\n",
    "    l2_norm = cp.sum_squares(w)\n",
    "    logloss = cp.sum(cp.multiply(y, (X @ w)) - cp.logistic(X @ w))\n",
    "    prob = cp.Problem(cp.Minimize(-logloss + c_1 * R_FP + c_2 * R_FN + gamma * l2_norm))\n",
    "    prob.solve(solver='ECOS', verbose=False,max_iters=1000)\n",
    "    \n",
    "    solution = {\n",
    "        'w': w.value,\n",
    "        'log_likelihood': logloss.value,\n",
    "        'R_FN': R_FN.value,\n",
    "        'R_FP': R_FP.value,\n",
    "        'objective': -logloss.value + c_1 * R_FP.value + c_2 * R_FN.value + gamma * l2_norm\n",
    "    }\n",
    "    \n",
    "    return solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48df164",
   "metadata": {},
   "source": [
    "## Visualization Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d8c0faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7259/729434132.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[header].replace(transform[header], inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[1, 34, 0, 0, 1],\n",
       "        [1, 24, 0, 4, 1],\n",
       "        [1, 23, 0, 1, 1],\n",
       "        ...,\n",
       "        [1, 23, 0, 0, 1],\n",
       "        [1, 23, 0, 0, 1],\n",
       "        [1, 33, 1, 3, 0]], dtype=object),\n",
       " array([1, 1, 0, ..., 0, 0, 0]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_compas, y_compas = process_data(dataset['compas'], fmt['compas'], transform['compas'])\n",
    "X_compas, y_compas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79eb5ce6",
   "metadata": {},
   "source": [
    "## FPR & FNR Considerations\n",
    "\n",
    "### Only FPR\n",
    "\n",
    "- $d_0 = 1$, $d_1$ = 0. Thus only activating $c_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b35a9682",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem['compas']['fn']=False\n",
    "problem['compas']['fp']=True\n",
    "\n",
    "## Solve the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ece6d96",
   "metadata": {},
   "source": [
    "### Only FNR\n",
    "\n",
    "- $d_0 = 0$, $d_1 = 1$. Thus, only activating $c_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4da06521",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem['compas']['fn']=True\n",
    "problem['compas']['fp']=False\n",
    "\n",
    "\n",
    "## Solve the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed430f20",
   "metadata": {},
   "source": [
    "### Both FPR and FNR\n",
    "\n",
    "- $d_0 = 1$, $d_1 = 1$. Thus, activating $c_1 = c_2 = c$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0288f1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem['compas']['fn']=True\n",
    "problem['compas']['fp']=True\n",
    "\n",
    "\n",
    "## Solve the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f0effa",
   "metadata": {},
   "source": [
    "## Vanilla Regularizer\n",
    "\n",
    "- $d_0 = 0$, $d_1 = 0$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6a0944fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem['compas']['fn']=False\n",
    "problem['compas']['fp']=False\n",
    "\n",
    "\n",
    "## Solve the problem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
